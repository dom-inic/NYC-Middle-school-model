{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "NYC_middle_school.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# loading the dataset \n",
        "# loading from google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "cqAXHUi1_PyI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# read the data using pandas\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/NYC/middleSchoolData.csv\")\n",
        "data.head()"
      ],
      "outputs": [],
      "metadata": {
        "id": "X68aZS_AE8_Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# trying another method to load the data from google drive\n",
        "from google.colab import files \n",
        "uploaded = files.upload()"
      ],
      "outputs": [],
      "metadata": {
        "id": "2HroE9IcGV-U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "# include path to dataset if not using google colab\n",
        "# data = pd.read_csv('/path/....')\n",
        "data = pd.read_csv('middleSchoolData.csv')\n",
        "data.head()"
      ],
      "outputs": [],
      "metadata": {
        "id": "2lPsFw2RGwg0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data.info()"
      ],
      "outputs": [],
      "metadata": {
        "id": "e6z8tF-_Hr5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# dataset got alot of missing values that need to be taken care off\n",
        "data.describe()"
      ],
      "outputs": [],
      "metadata": {
        "id": "TaT8u1yaH8u8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# plottng the data using a histogram to show the number of instances on the y and x gven range\n",
        "import matplotlib.pyplot as plt\n",
        "data.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "q1oi_BJTyzYq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Question 1\n",
        "# correlation between the number of applications and admissions to HSPHS?\n",
        "# splitting the data to fit to the models later\n",
        "X = data[\"applications\"].values.reshape(-1, 1)\n",
        "Y = data[\"acceptances\"]"
      ],
      "outputs": [],
      "metadata": {
        "id": "7WVEOHILzHN0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# visualizing applications against acceptance\n",
        "# plot\n",
        "plt.plot(data[\"applications\"], data[\"acceptances\"], 'o',\n",
        "         markersize=2)\n",
        "plt.xlabel('applications')\n",
        "plt.ylabel('acceptances')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Uz5V9tqM_wlI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# adding regression line to visualization for better corr\n",
        "# regression model from sklearn \n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "regres = LinearRegression()\n",
        "regres.fit(X, Y)\n",
        "reg_sqr = regres.score(X, Y)\n",
        "r = np.sqrt(reg_sqr)\n",
        "betas = regres.coef_  \n",
        "y_int = regres.intercept_ \n",
        "\n",
        "y_hat = betas[0] * data[\"applications\"] + \\\n",
        "    y_int \n",
        "# slope-intercept form, y = mx + b\n",
        "plt.plot(data[\"applications\"], y_hat, color='orange', linewidth=0.5,)\n",
        "# add title, r-squared rounded to nearest thousandth\n",
        "plt.title('R^2: {:.3f}, R: {:.3f}'.format(reg_sqr, r))"
      ],
      "outputs": [],
      "metadata": {
        "id": "TFRwcUo2ALxN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# r=0.802\n",
        "# using pandas scatter_matrix function to check for correlation btn attributes\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "attributes = [ \"applications\",\"acceptances\"]\n",
        "scatter_matrix(data[attributes], figsize=(12,8))"
      ],
      "outputs": [],
      "metadata": {
        "id": "LUxFI2nZJ6Y7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above out we can see that the correlation between applications and acceptances is greater."
      ],
      "metadata": {
        "id": "eA31ZYRjRNIC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Question 2\n",
        "# better predictor of admission to HSPHS\n",
        "# lets have a look at the atrributes\n",
        "\n",
        "data.info()"
      ],
      "outputs": [],
      "metadata": {
        "id": "WzQAx0WkLuWG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# taking care of missing values using the imputer class\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Imputation\n",
        "my_imputer = SimpleImputer()\n",
        "imputed_data = pd.DataFrame(my_imputer.fit_transform(data))\n",
        "\n",
        "# Imputation removed column names; put them back\n",
        "imputed_data.columns = data.columns\n",
        "\n",
        "data.info()"
      ],
      "outputs": [],
      "metadata": {
        "id": "6L9AxBhNRz4v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# impute strategy wont work with categorical variables \n",
        "# trying dropna\n",
        "# drop row with missing school size in tmp\n",
        "tmp = data[[\"applications\", \"school_size\", \"acceptances\"]]\n",
        "tmp = tmp.dropna()\n",
        "\n",
        "X = (tmp[\"applications\"] /\n",
        "     tmp[\"school_size\"]).values.reshape(-1, 1)\n",
        "Y = tmp[\"acceptances\"]\n",
        "\n",
        "# Plot application rates against acceptances\n",
        "plt.plot(tmp[\"applications\"] /\n",
        "         tmp[\"school_size\"], tmp[\"acceptances\"], 'o',\n",
        "         markersize=2)  \n",
        "plt.xlabel('application rates')\n",
        "plt.ylabel('acceptances')\n",
        "\n",
        "#Add regression line to visualization\n",
        "# slope-intercept form, y = mx + b\n",
        "y_hat = betas[0] * tmp[\"applications\"] / tmp[\"school_size\"] + \\\n",
        "    y_int \n",
        "plt.plot(tmp[\"applications\"] / tmp[\"school_size\"],\n",
        "         y_hat, color='orange', linewidth=0.5)\n",
        "# add title, r-squared rounded to nearest thousandth\n",
        "plt.title('R^2: {:.3f}, R: {:.3f}'.format(reg_sqr, r))  # r = 0.802"
      ],
      "outputs": [],
      "metadata": {
        "id": "N33Lq_VzSirD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# using the correlation it turns out that number of applications\n",
        "# is a better predictor as compared to acceptance rate\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "BXbWguXxWJ_J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Question 3\n",
        "# Which school has the best *per student* odds of sending someone to HSPHS?\n",
        "\n",
        "# drop row with missing school size in tmp\n",
        "tmp = data[[\"school_name\", \"school_size\", \"acceptances\"]]\n",
        "tmp = tmp.dropna()\n",
        "\n",
        "# greater probability always result in greater odd, so we only need to find out\n",
        "# schools with the highest proportion of student being admitted to HSPHS\n",
        "\n",
        "tmp.loc[(tmp[\"acceptances\"] / tmp[\"school_size\"]).idxmax()]"
      ],
      "outputs": [],
      "metadata": {
        "id": "foPe7WTuYksp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above output, it is evident that CHRISTA MCAULIFFE SCHOOL\\I.S has the best odds per student of sending someone to HSPHS."
      ],
      "metadata": {
        "id": "B-g9qkMFZUfK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Question 4\n",
        "# relationship between how students perceive their school (as reported in columns\n",
        "# L-Q) and how the school performs on objective measures of achievement (as noted in\n",
        "# columns V-X)\n",
        "\n",
        "# \"school climate factors\", drop row with missing data\n",
        "climate = data.iloc[:, 11:17]\n",
        "climate = climate.dropna()\n",
        "\n",
        "# Z-score the data:\n",
        "from scipy import stats\n",
        "zscored_cilmate = stats.zscore(climate)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QTeqMtLcZH9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# PCA to reduce number of dimension to 1\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA()\n",
        "pca.fit(zscored_cilmate)\n",
        "\n",
        "eig_vals = pca.explained_variance_\n",
        "loadings = pca.components_\n",
        "rotated_data = pca.fit_transform(zscored_cilmate)"
      ],
      "outputs": [],
      "metadata": {
        "id": "xJMkW7t2bfaT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# plot of a bar graph of eigenvalues\n",
        "plt.bar(np.linspace(1, 6, 6), eig_vals)\n",
        "plt.xlabel('Principal component')\n",
        "plt.ylabel('Eigenvalue')\n",
        "plt.plot([1, 6], [1, 1], color='red',\n",
        "         linewidth=1)  # Kaiser criterion line\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "AQFfLElscEZu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# add back to the temporary dataframe first to restore the index in the original\n",
        "# dataframe (we drop some data but want to keep orginal index)\n",
        "\n",
        "# sometime PCA will flip the sign, we need to flip it back to make this rating\n",
        "# intuitive (higher is better)\n",
        "climate[\"climate_rating\"] = -rotated_data[:, 0]\n",
        "\n",
        "# insert to original data frame\n",
        "data[\"climate_rating\"] = climate[\"climate_rating\"]\n",
        "\n",
        "# \"measures of achievement\", drop row with missing data\n",
        "achievement = data.iloc[:, 21:24]\n",
        "achievement = achievement.dropna()\n",
        "\n",
        "# Z-score the data:\n",
        "zscored_achievement = stats.zscore(achievement)\n",
        "\n",
        "# do a PCA to reduce number of dimension to 1\n",
        "pca = PCA()\n",
        "pca.fit(zscored_achievement)\n",
        "\n",
        "eig_vals = pca.explained_variance_\n",
        "loadings = pca.components_\n",
        "rotated_data = pca.fit_transform(zscored_achievement)"
      ],
      "outputs": [],
      "metadata": {
        "id": "r-wqkHM6cZUv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# What a scree plot is: Plotting a bar graph of the sorted Eigenvalues\n",
        "plt.figure()\n",
        "plt.bar(np.linspace(1, 3, 3), eig_vals)\n",
        "plt.xlabel('Principal component')\n",
        "plt.ylabel('Eigenvalue')\n",
        "plt.plot([1, 3], [1, 1], color='red',\n",
        "         linewidth=1)  # Kaiser criterion line"
      ],
      "outputs": [],
      "metadata": {
        "id": "T_84CijLcwWg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# add back to the temporary dataframe first to restore the index in the original\n",
        "# dataframe (we drop some data but want to keep orginal index)\n",
        "achievement[\"achievement_rating\"] = rotated_data[:, 0]\n",
        "\n",
        "# insert to original data frame\n",
        "data[\"achievement_rating\"] = achievement[\"achievement_rating\"]\n",
        "\n",
        "# finally, do a simple regression\n",
        "tmp = data[[\"climate_rating\", \"achievement_rating\"]]\n",
        "tmp = tmp.dropna()\n",
        "\n",
        "X = tmp[\"climate_rating\"].values.reshape(-1, 1)\n",
        "Y = tmp[\"achievement_rating\"]\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(tmp[\"climate_rating\"], tmp[\"achievement_rating\"], 'o',\n",
        "         markersize=2)  # Plot application rates against acceptances\n",
        "plt.xlabel('climate ratings')\n",
        "plt.ylabel('achievement ratings')"
      ],
      "outputs": [],
      "metadata": {
        "id": "wmwuLa4IdyOI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Adding regression line to visualization:\n",
        "y_hat = betas[0] * tmp[\"climate_rating\"] + \\\n",
        "    y_int\n",
        "# slope-intercept form, y = mx + b\n",
        "plt.plot(tmp[\"climate_rating\"], y_hat, color='orange', linewidth=0.5)\n",
        "\n",
        "# add title, r-squared rounded to nearest thousandth\n",
        "plt.title('R^2: {:.3f}, R: {:.3f}'.format(reg_sqr, r))"
      ],
      "outputs": [],
      "metadata": {
        "id": "GoxahINVRv4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is evident that their is a relationship between how students perceive their school and how the school performs. "
      ],
      "metadata": {
        "id": "mEaKj9zBThnL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Question 5\n",
        "# which kind of school\n",
        "# performs differently than another kind either on some dependent measure, e.g. objective\n",
        "# measures of achievement or admission to HSPHS.\n",
        "\n",
        "# using acceptance rate instead of raw acceptance numbers\n",
        "data[\"acceptance_rate\"] = data[\"acceptances\"] / \\\n",
        "    data[\"applications\"]\n",
        "\n",
        "# creating a binary indicator for poor and rich schools\n",
        "median_spending = data[\"per_pupil_spending\"].median()\n",
        "data[\"rich_school\"] = data[\"per_pupil_spending\"] > median_spending\n",
        "\n",
        "# drop row with missing data in tmp\n",
        "tmp = data[[\"rich_school\", \"achievement_rating\"]]\n",
        "tmp = tmp.dropna()\n",
        "\n",
        "rich = tmp[tmp[\"rich_school\"] == 1][\"achievement_rating\"]\n",
        "poor = tmp[tmp[\"rich_school\"] == 0][\"achievement_rating\"]\n",
        "u_rich_achievement, p_rich_achievement = stats.mannwhitneyu(rich, poor)\n",
        "p_rich_achievement\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "Xz4BfDngS2vL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# dropping row with missing data in tmp\n",
        "tmp = data[[\"rich_school\", \"acceptance_rate\"]]\n",
        "tmp = tmp.dropna()\n",
        "\n",
        "rich = tmp[tmp[\"rich_school\"] == 1][\"acceptance_rate\"]\n",
        "poor = tmp[tmp[\"rich_school\"] == 0][\"acceptance_rate\"]\n",
        "u_rich_acceptance, p_rich_acceptance = stats.mannwhitneyu(rich, poor)\n",
        "p_rich_acceptance"
      ],
      "outputs": [],
      "metadata": {
        "id": "rYYCfnybXe0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conducted mann-whittney u test on the performance of rich and poor schools on achievement rating and accpetance rates, which resulted in exteremely small p-values. \n",
        "This shows that poor schools and rich schools are extremely likely to perform differently when it comes to objective measures of achievements and admission to HSPHS"
      ],
      "metadata": {
        "id": "9aKcAAuiaklR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Question 6 \n",
        "# evidence that the availability of material resources (e.g. per student spending\n",
        "# or class size) impacts objective measures of achievement or admission to HSPHS?\n",
        "\n",
        "# per pupil spending against achievement ratings\n",
        "# drop row with missing data in tmp\n",
        "tmp = data[[\"per_pupil_spending\", \"achievement_rating\"]]\n",
        "tmp = tmp.dropna()\n",
        "\n",
        "X = tmp[\"per_pupil_spending\"].values.reshape(-1, 1)\n",
        "Y = tmp[\"achievement_rating\"]\n",
        "\n",
        "regr = LinearRegression().fit(X, Y)\n",
        "r_sqr = regr.score(X, Y)\n",
        "r = np.sqrt(r_sqr)\n",
        "betas = regr.coef_  # m\n",
        "y_int = regr.intercept_  # b\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(tmp[\"per_pupil_spending\"], tmp[\"achievement_rating\"], 'o',\n",
        "         markersize=2)  # Plot per pupil spending against achievement ratings\n",
        "plt.xlabel('spending per pupil')\n",
        "plt.ylabel('achievement ratings')"
      ],
      "outputs": [],
      "metadata": {
        "id": "wo1rc4S4aDY2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Add regression line to visualization:\n",
        "y_hat = betas[0] * tmp[\"per_pupil_spending\"] + \\\n",
        "    y_int  # slope-intercept form, y = mx + b\n",
        "plt.plot(tmp[\"per_pupil_spending\"], y_hat, color='orange', linewidth=0.5)\n",
        "\n",
        "# add title, r-squared rounded to nearest thousandth\n",
        "plt.title('R^2: {:.3f}, R: {:.3f}'.format(r_sqr, r))"
      ],
      "outputs": [],
      "metadata": {
        "id": "ULODvS6Ico6J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# per pupil spending against acceptance rate\n",
        "# drop row with missing data in tmp\n",
        "tmp = data[[\"per_pupil_spending\", \"acceptance_rate\"]]\n",
        "tmp = tmp.dropna()\n",
        "\n",
        "X = tmp[\"per_pupil_spending\"].values.reshape(-1, 1)\n",
        "Y = tmp[\"acceptance_rate\"]\n",
        "\n",
        "regr = LinearRegression().fit(X, Y)\n",
        "r_sqr = regr.score(X, Y)\n",
        "r = np.sqrt(r_sqr)\n",
        "betas = regr.coef_  # m\n",
        "y_int = regr.intercept_  # b\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(tmp[\"per_pupil_spending\"], tmp[\"acceptance_rate\"], 'o',\n",
        "         markersize=2)  # Plot per pupil spending against acceptance rate\n",
        "plt.xlabel('spending per pupil')\n",
        "plt.ylabel('acceptance rate')"
      ],
      "outputs": [],
      "metadata": {
        "id": "B-96qx0Sc2UJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Add regression line to visualization:\n",
        "y_hat = betas[0] * tmp[\"per_pupil_spending\"] + \\\n",
        "    y_int  # slope-intercept form, y = mx + b\n",
        "plt.plot(tmp[\"per_pupil_spending\"], y_hat, color='orange', linewidth=0.5)\n",
        "\n",
        "# add title, r-squared rounded to nearest thousandth\n",
        "plt.title('R^2: {:.3f}, R: {:.3f}'.format(r_sqr, r))"
      ],
      "outputs": [],
      "metadata": {
        "id": "6yrJlHjodLd4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# average class sizes against achievement ratings\n",
        "# drop row with missing data in tmp\n",
        "tmp = data[[\"avg_class_size\", \"achievement_rating\"]]\n",
        "tmp = tmp.dropna()\n",
        "\n",
        "X = tmp[\"avg_class_size\"].values.reshape(-1, 1)\n",
        "Y = tmp[\"achievement_rating\"]\n",
        "\n",
        "regr = LinearRegression().fit(X, Y)\n",
        "r_sqr = regr.score(X, Y)\n",
        "r = np.sqrt(r_sqr)\n",
        "betas = regr.coef_  # m\n",
        "y_int = regr.intercept_  # b\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(tmp[\"avg_class_size\"], tmp[\"achievement_rating\"], 'o',\n",
        "         markersize=2)  # Plot average class sizes against achievement ratings\n",
        "plt.xlabel('average class size')\n",
        "plt.ylabel('achievement ratings')"
      ],
      "outputs": [],
      "metadata": {
        "id": "n8Y2II3WdQhR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Add regression line to visualization:\n",
        "y_hat = betas[0] * tmp[\"avg_class_size\"] + \\\n",
        "    y_int  # slope-intercept form, y = mx + b\n",
        "plt.plot(tmp[\"avg_class_size\"], y_hat, color='orange', linewidth=0.5)\n",
        "\n",
        "# add title, r-squared rounded to nearest thousandth\n",
        "plt.title('R^2: {:.3f}, R: {:.3f}'.format(r_sqr, r))"
      ],
      "outputs": [],
      "metadata": {
        "id": "AfKhhHrMdab8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# average class sizes against acceptance rate\n",
        "# drop row with missing data in tmp\n",
        "tmp = data[[\"avg_class_size\", \"acceptance_rate\"]]\n",
        "tmp = tmp.dropna()\n",
        "\n",
        "X = tmp[\"avg_class_size\"].values.reshape(-1, 1)\n",
        "Y = tmp[\"acceptance_rate\"]\n",
        "\n",
        "regr = LinearRegression().fit(X, Y)\n",
        "r_sqr = regr.score(X, Y)\n",
        "r = np.sqrt(r_sqr)\n",
        "betas = regr.coef_  # m\n",
        "y_int = regr.intercept_  # b\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(tmp[\"avg_class_size\"], tmp[\"acceptance_rate\"], 'o',\n",
        "         markersize=2)  # Plot average class sizes against acceptances\n",
        "plt.xlabel('average class size')\n",
        "plt.ylabel('acceptance rate')"
      ],
      "outputs": [],
      "metadata": {
        "id": "MqaUMxkjdfon"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Add regression line to visualization:\n",
        "y_hat = betas[0] * tmp[\"avg_class_size\"] + \\\n",
        "    y_int  # slope-intercept form, y = mx + b\n",
        "plt.plot(tmp[\"avg_class_size\"], y_hat, color='orange', linewidth=0.5)\n",
        "\n",
        "# add title, r-squared rounded to nearest thousandth\n",
        "plt.title('R^2: {:.3f}, R: {:.3f}'.format(r_sqr, r))"
      ],
      "outputs": [],
      "metadata": {
        "id": "dZ3946Ldd_lI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the Above plots, there's no evidence that the availability of material resources impacts object measures of achievement: the smaller the class and higher spending per pupil, the lower the achievement ratings and HSPHS acceptance rate, which is very unexpected. It is possible that there are some confounding factors we didn't rule out lead to this result. \n",
        "It is also possible that class size and per pupil spending from school does not matter too much because the availability of material resources for students is typically not determined by school, but  by their family. Perhaps the percentage of students living in households below the poverty line will better represent students' access to material resources in this case. "
      ],
      "metadata": {
        "id": "T7WZC-3eeUtb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Question 7\n",
        "# proportion of schools accounts for 90% of all students accepted to HSPHS? \n",
        "# normalizing to get the percentage\n",
        "sorted_acceptance = data[[\"acceptances\",\n",
        "                                 \"school_name\"]].sort_values(by=\"acceptances\",\n",
        "                                                             ascending=False)\n",
        "normalized_sorted_accptance = sorted_acceptance[\"acceptances\"] / \\\n",
        "    sorted_acceptance[\"acceptances\"].sum()\n",
        "\n",
        "plt.bar(sorted_acceptance[\"school_name\"][:20], normalized_sorted_accptance[:20])\n",
        "plt.xlabel('school')\n",
        "plt.ylabel('% of total acceptance')\n",
        "\n",
        "labels = sorted_acceptance[\"school_name\"][:20]\n",
        "plt.xticks(np.linspace(0, 19, 20), labels, rotation=\"vertical\")\n",
        "\n",
        "accumulated_percentage = normalized_sorted_accptance.cumsum()\n",
        "\n",
        "sum(accumulated_percentage < 0.9) / len(accumulated_percentage)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VxXhwvsteS4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the ouput above, about 20.5% of schools account for 905 of students accepted to HSPHSs"
      ],
      "metadata": {
        "id": "H85KhpJAgbAv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Question 8\n",
        "# Building the model\n",
        "# Using regression model\n",
        "# ethnicity identity is not included because one of these columns could be\n",
        "# determined by other colunmns and it is not possible to reduce the dimension\n",
        "# on these coulumns. They may break the validity of this prediction model.\n",
        "glm_data = data[[\"per_pupil_spending\",\n",
        "                        \"avg_class_size\", \"disability_percent\",\n",
        "                        \"climate_rating\", \"poverty_percent\", \"ESL_percent\",\n",
        "                        \"school_size\", \"climate_rating\", \"acceptance_rate\",\n",
        "                        \"achievement_rating\"]]\n",
        "glm_data = glm_data.dropna()\n",
        "\n",
        "# to tell which factor is most important, we need to z-score the data\n",
        "zscored_glm_data = stats.zscore(glm_data)\n",
        "\n",
        "X = zscored_glm_data[:, :-2]\n",
        "Y = zscored_glm_data[:, -2]\n",
        "\n",
        "regr = LinearRegression().fit(X, Y)\n",
        "betas = regr.coef_  # m\n",
        "y_int = regr.intercept_  # b\n",
        "\n",
        "plt.bar(np.linspace(0, 8, 8), betas)\n",
        "plt.xlabel('variables')\n",
        "plt.ylabel('betas')\n",
        "\n",
        "labels = [\"per_pupil_spending\",\n",
        "          \"avg_class_size\", \"disability_percent\",\n",
        "          \"climate_rating\", \"poverty_percent\", \"ESL_percent\",\n",
        "          \"school_size\", \"climate_rating\"]\n",
        "plt.xticks(np.linspace(0, 8, 8), labels, rotation=45)\n",
        "plt.title(\"Beta coefficients of each variable for prediting acceptance rate\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "xdJMWZZrgFB6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "Y = zscored_glm_data[:, -1]\n",
        "\n",
        "regr = LinearRegression().fit(X, Y)\n",
        "betas = regr.coef_  # m\n",
        "y_int = regr.intercept_  # b\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(np.linspace(0, 8, 8), betas)\n",
        "plt.xlabel('variables')\n",
        "plt.ylabel('betas')\n",
        "\n",
        "labels = [\"per_pupil_spending\",\n",
        "          \"avg_class_size\", \"disability_percent\",\n",
        "          \"climate_rating\", \"poverty_percent\", \"ESL_percent\",\n",
        "          \"school_size\", \"climate_rating\"]\n",
        "plt.xticks(np.linspace(0, 8, 8), labels, rotation=45)\n",
        "plt.title(\n",
        "    \"Beta coefficients of each variable for predicting academic achievement\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "fCD5UClFidrr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " from the plots above, poverty rate is the determining factor on the HSPHS admission and achieving highs cores on objective measures of acceptance."
      ],
      "metadata": {
        "id": "3Q4PQ35cjPUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whole summary on the report for question 9 and 10 and all other questions"
      ],
      "metadata": {
        "id": "krmIPHFDjbiT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "Hy5e1vceivSP"
      }
    }
  ]
}